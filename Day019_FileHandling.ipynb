{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAY 19"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises: Level 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1: Write a function which count number of lines and number of words in a text. All the files are in the data folder: a) Read obama_speech.txt file and count number of lines and words b) Read michelle_obama_speech.txt file and count number of lines and words c) Read donald_speech.txt file and count number of lines and words d) Read melina_trump_speech.txt file and count number of lines and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import csv\n",
    "import sys  \n",
    "sys.path.append(\"data\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of lines and words in the file are 30 and 1241 respectively\n",
      "The number of lines and words in the file are 14 and 471 respectively\n",
      "The number of lines and words in the file are 188 and 1141 respectively\n",
      "The number of lines and words in the file are 41 and 1778 respectively\n"
     ]
    }
   ],
   "source": [
    "def count_words_lines(file):\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        words = []\n",
    "        for line in lines:\n",
    "            line = re.sub(r'[^\\w\\s]','',line)\n",
    "            words.extend(line.split())\n",
    "    print(f'The number of lines and words in the file are {len(lines)} and {len(words)} respectively')\n",
    "count_words_lines('C:\\\\Users\\\\R I DIKKO\\\\Arewads\\\\TafawaBalewa_IndependenceSpeech.txt')\n",
    "count_words_lines('C:\\\\Users\\\\R I DIKKO\\\\Arewads\\\\Sardauna_Speeches.txt')\n",
    "count_words_lines('C:\\\\Users\\\\R I DIKKO\\\\Arewads\\\\MurtalaMuhammad_Speech.txt')\n",
    "count_words_lines('C:\\\\Users\\\\R I DIKKO\\\\Arewads\\\\MallamAminuKano.txt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: Read the countries_data.json data file in data directory, create a function that finds the ten most spoken languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m     result \u001b[39m=\u001b[39m [(item[\u001b[39m1\u001b[39m],item[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m sorted_lang]\n\u001b[0;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m result[:n]\n\u001b[1;32m---> 15\u001b[0m \u001b[39mprint\u001b[39m(most_spoken_languages(\u001b[39m'\u001b[39;49m\u001b[39mC:\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mUsers\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mR I DIKKO\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mArewads\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mCountries_data.json\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m10\u001b[39;49m))\n\u001b[0;32m     16\u001b[0m \u001b[39mprint\u001b[39m(most_spoken_languages(\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mUsers\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mR I DIKKO\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mArewads\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mCountries_data.json\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m3\u001b[39m))\n",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m, in \u001b[0;36mmost_spoken_languages\u001b[1;34m(file, n)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(file) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      3\u001b[0m     lines \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mreadlines()\n\u001b[1;32m----> 4\u001b[0m     \u001b[39mlist\u001b[39m \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(f\u001b[39m.\u001b[39mread())\n\u001b[0;32m      5\u001b[0m \u001b[39m# looping to get dict of languages\u001b[39;00m\n\u001b[0;32m      6\u001b[0m languages \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "def most_spoken_languages(file,n):\n",
    "    with open(file) as f:\n",
    "        list = json.loads(f.read())\n",
    "    # looping to get dict of languages\n",
    "    languages = []\n",
    "    for i in range(len(list)):\n",
    "        languages.extend(list[i]['languages'])\n",
    "    lang = {}\n",
    "    for language in languages:\n",
    "        lang[language] = lang.get(language,0) + 1\n",
    "    sorted_lang = sorted(lang.items(), key= lambda x:x[1],reverse=True) \n",
    "    result = [(item[1],item[0]) for item in sorted_lang]\n",
    "    return result[:n]\n",
    "print(most_spoken_languages('C:\\\\Users\\\\R I DIKKO\\\\Arewads\\\\Countries_data.json',10))\n",
    "print(most_spoken_languages('C:\\\\Users\\\\R I DIKKO\\\\Arewads\\\\Countries_data.json',3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3: Read the countries_data.json data file in data directory, create a function that creates a list of the ten most populated countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'countries_data.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     final_list \u001b[39m=\u001b[39m [{\u001b[39m'\u001b[39m\u001b[39mcountry\u001b[39m\u001b[39m'\u001b[39m:item[\u001b[39m0\u001b[39m],\u001b[39m'\u001b[39m\u001b[39mpopulation\u001b[39m\u001b[39m'\u001b[39m:item[\u001b[39m1\u001b[39m]} \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m sorted_lt]\n\u001b[0;32m     11\u001b[0m     \u001b[39mreturn\u001b[39;00m final_list[:n]\n\u001b[1;32m---> 13\u001b[0m most_populated_countries(\u001b[39m'\u001b[39;49m\u001b[39mcountries_data.json\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m10\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m, in \u001b[0;36mmost_populated_countries\u001b[1;34m(filename, n)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmost_populated_countries\u001b[39m(filename,n):\n\u001b[1;32m----> 2\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filename) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      3\u001b[0m         dic_list \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(f\u001b[39m.\u001b[39mread())\n\u001b[0;32m      4\u001b[0m     population \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\R I DIKKO\\anaconda3\\envs\\arewads\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'countries_data.json'"
     ]
    }
   ],
   "source": [
    "def most_populated_countries(filename,n):\n",
    "    with open(filename) as f:\n",
    "        dic_list = json.loads(f.read())\n",
    "    population = dict()\n",
    "    for i in range(len(dic_list)):\n",
    "        keys = dic_list[i]['name']\n",
    "        values = dic_list[i]['population']\n",
    "        population[keys] = values\n",
    "    sorted_lt = sorted(population.items(), key= lambda x:x[1],reverse=True)\n",
    "    final_list = [{'country':item[0],'population':item[1]} for item in sorted_lt]\n",
    "    return final_list[:n]\n",
    "\n",
    "most_populated_countries('Countries_data.json',10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises: Level 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4: Extract all incoming email addresses as a list from the email_exchange_big.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_common_words(file,n=10):\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "    words = []\n",
    "    for line in lines:\n",
    "        line = re.sub(r'[^\\w\\s]','',line)\n",
    "        words.extend(line.split())\n",
    "    words_dict = {}\n",
    "    for word in words:\n",
    "        words_dict[word] = words_dict.get(word,0) + 1\n",
    "    words_sorted = sorted(words_dict.items(),key=lambda x:x[1],reverse=True)\n",
    "    result = [(word[1],word[0]) for word in words_sorted]\n",
    "    return result[:n]\n",
    "\n",
    "find_most_common_words('donald_speech.txt',5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5: Find the most common words in the English language. Call the name of your function find_most_common_words, it will take two parameters - a string or a file and a positive integer, indicating the number of words. Your function will return an array of tuples in descending order. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6: Use the function, find_most_frequent_words to find: a) The ten most frequent words used in Obama's speech b) The ten most frequent words used in Michelle's speech c) The ten most frequent words used in Trump's speech d) The ten most frequent words used in Melina's speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Obama: ',find_most_common_words('obama_speech.txt')) \n",
    "print('Michelle Obama: ',find_most_common_words('michelle_obama_speech.txt'))\n",
    "print('Donald Trump: ',find_most_common_words('donald_speech.txt'))\n",
    "print('Melania Trump: ',find_most_common_words('melania_trump_speech.txt'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7: Write a python application that checks similarity between two texts. It takes a file or a string as a parameter and it will evaluate the similarity of the two texts. For instance check the similarity between the transcripts of Michelle's and Melina's speech. You may need a couple of functions, function to clean the text(clean_text), function to remove support words(remove_support_words) and finally to check the similarity(check_text_similarity). List of stop words are in the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_text_similarity(list_one,list_two):\n",
    "    res = [x for x in (list_one + list_two) if x in list_one and x in list_two]\n",
    "    similar_words_percent = (len(res)/(len(list_one) + len(list_two))) * 100\n",
    "    return similar_words_percent\n",
    "check_text_similarity(['apple','banana','mango','pawpaw'],['apple','mango','pear']) \n",
    "\n",
    "def comparing_text_in_file_similarity(file_one,file_two):\n",
    "    file_one_words = remove_stop_words(clean_text(file_one))\n",
    "    file_two_words = remove_stop_words(clean_text(file_two))\n",
    "    return check_text_similarity(file_one_words,file_two_words)\n",
    "\n",
    "comparing_text_in_file_similarity('michelle_obama_speech.txt','melania_trump_speech.txt') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 8: Find the 10 most repeated words in the romeo_and_juliet.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9: Read the hacker news csv file and find out: a) Count the number of lines containing python or Python b) Count the number lines containing JavaScript, javascript or Javascript c) Count the number lines containing Java and not JavaScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hacker_news.csv',newline='') as f:\n",
    "    csv_reader = csv.reader(f,delimiter=',')\n",
    "    python_rows = 0\n",
    "    javascript_rows = 0\n",
    "    java_rows = 0\n",
    "    for row in csv_reader:\n",
    "        for i in range(len(row)):\n",
    "            if re.findall(r'[Pp]ython',row[i]):\n",
    "                python_rows += 1\n",
    "            elif re.findall(r'[Jj]ava[Ss]cript',row[i]):\n",
    "                javascript_rows +=1\n",
    "            elif re.findall(r'Java$',row[i]):\n",
    "                java_rows +=1\n",
    "print(f'the number of lines containing a,b and c respectively are: {python_rows}, {javascript_rows}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arewads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
